\section{Implementation}

\subsection{High level overview}

\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{images/Interconnect_architecture.png}
\caption{Overview interconnect architecture}\label{fig:firmware-system}
\end{figure}

A high level overview is given in \Cref{fig:firmware-system}. The system contains four main parts: the MCU, the co-processor, video output and the AXI bus to connect everything together.

The MCU contains data for the image to be processed, inside DDR3 RAM. It splits the image data into four quadrants, and sends the corresponding pixels for each quadrant to the co-processor via AXI.

The processed image is sent from the co-processor to the MCU via AXI. The MCU then sends it to the video pipeline to display the image.

\subsection{Convolution unit}

The convolution unit is the heart of our system. It loads pixels into its buffer, and calculates the result of each pixel when the buffers are full enough. The system is shown in \Cref{fig:convolution_unit_mcu}.

Some kernels require fractional coefficients. This is implemented as a bit shift at the end of the calculation. This is not a catch-all solution, as only divisions by $2^n$ can be constructed, but it's much easier to implement and faster than using fixed-point or floating-point arithmetic.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{images/convolution_unit_mcu.png}
    \caption{Convolution unit schematic}
    \label{fig:convolution_unit_mcu}
\end{figure}

The convolution unit contains three buffers, each 640 pixels in length. A pixel is shifted into the lower buffer each clock cycle. When the buffer is full, ejected bits are inserted into the middle buffer. When the middle buffer is full, the pixels are shifted into the upper buffer. This nicely arranges the pixels, allowing the module to ingest pixels from three image rows simultaneously.

To further increase speed, the convolution process is pipelined.

\begin{enumerate}
    \item Stage 1: Calculate $P_1 c_1$, $P_2 c_2$, $P_3 c_3$ in parallel
    \item Stage 2: Calculate $P_1 c_1 + P_2 c_2$
    \item Stage 3: Calculate $P_1 c_1 + P_2 c_2 + P_3 c_3$
    \item Stage 4: Calculate $(P_1 c_1 + P_2 c_2 + P_3 c_3) >> s$
\end{enumerate}

The convolution unit RTL module exposes inputs for the kernel coefficients, and the bit shift that is applied after the convolution step. This makes the kernel configurable at runtime.

\subsection{Effect of block size}

To calculate the convolution of a block of size $n$ by $n$ pixels, we need the surrounding pixels as well, as shown in \Cref{fig:pixel_block_size}. To calculate the convolution for the $n^2$ pixels, we need to fetch $(n+2)^2$ pixels, making the efficiency $\eta = \frac{n^2}{(n+1)^2}$. A plot of this function is shown in \Cref{fig:effect_of_block_size_graph}. For low block sizes, there are a lot of pixels that overlap between adjacent blocks, resulting in wasted re-fetching. However, larger block sizes mean less parallelism, resulting in a slower system.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.15\textwidth]{images/screenshot_pixel_block_size.png}
    \caption{Pixels to calculate (blue) and apron (grey)}
    \label{fig:pixel_block_size}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            title={Efficiency versus block size},
            axis lines = left,
            xlabel = \(n\),
            ylabel = {\(\eta\)},
        ]
            \addplot [
                domain=0:20, 
                samples=100, 
                color=red,
            ]
            {x^2 / ((x+2)^2)};
        \end{axis}
    \end{tikzpicture}
    \caption{Efficiency versus block size}
    \label{fig:effect_of_block_size_graph}
\end{figure}



\subsection{Video Pipeline}

The idea to be able to showcase the co-processor was to display the unprocessed and processed images on a screen with timing information using VGA. This was implemented using existing Vivado AXI periherial IPs shown in figure \Cref{fig:video-pipeline}. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{images/Video_pipeline_architecture.png}
    \caption{Video Pipeline Overview}
    \label{fig:video-pipeline}
\end{figure}

We can see three blocks. 

\subsubsection{Video Timing Controller}

To generate a 640x480p video signal at 60\,Hz, a pixel clock of 25.175\,MHz is required according to the VGA timing specification. This clock determines the rate at which individual pixels are transmitted. Each clock cycle corresponds to one pixel period, including both the active video region and the blanking intervals.

Following the specifications the following parameters where set in the controller seen in \Cref{tab:vga_timing}.

\begin{table}[h]
\centering
\caption{VGA 640Ã—480 @ 60\,Hz Timing Parameters}
\label{tab:vga_timing}
\begin{tabular}{lcc}
\hline
\textbf{Parameter} & \textbf{Horizontal (pixels)} & \textbf{Vertical (lines)} \\
\hline
Active video area & 640 & 480 \\
Front porch & 16 & 10 \\
Sync pulse width & 96 & 2 \\
Back porch & 48 & 33 \\
\hline
Total & 800 & 525 \\
\hline
\end{tabular}
\end{table}

In practice the pixel clock of 25.175\,MHz is not achivable exact but a clock of 25\,MHz was used and gives a small deviation in refresh rate. But this is all within the tolerance of standard VGA monitors.

\subsubsection{AXI Video Direct Memory Access}

To reduce the processing load on the CPU, an AXI Video Direct Memory Access (VDMA) controller is used to transfer video data directly between the DDR3 memory and the video pipeline. By offloading continuous frame transfers to dedicated hardware, the CPU remains available for higher-level control tasks.

The VDMA was configured to operate in memory-to-stream mode using three frame buffers. This multi-buffering scheme allows one frame to be displayed while another is being prepared or updated, reducing the risk of visual artifacts such as tearing. The controller is configured via software by providing the base addresses of the frame buffers loacated in DDR3 memory.

Once initialized, the VDMA autonomously handles the read transactions on the AXI bus and streams pixels data into the AXI-stream to Video out controller.

\subsubsection{AXI-Stream To Video Out}

The AXI-Stream To Video Out controller takes in the Video Timing signals and the stream from the VDMA Controller and synchronises these to output the correct VGA timing signals and pixels.
